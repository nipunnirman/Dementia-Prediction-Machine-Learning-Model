{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>NACCADC</th>\n",
       "      <th>PACKET</th>\n",
       "      <th>FORMVER</th>\n",
       "      <th>VISITMO</th>\n",
       "      <th>VISITDAY</th>\n",
       "      <th>VISITYR</th>\n",
       "      <th>NACCVNUM</th>\n",
       "      <th>NACCAVST</th>\n",
       "      <th>NACCNVST</th>\n",
       "      <th>...</th>\n",
       "      <th>INLIVWTH</th>\n",
       "      <th>NACCFAM</th>\n",
       "      <th>NACCMOM</th>\n",
       "      <th>NACCFADM</th>\n",
       "      <th>NACCAM</th>\n",
       "      <th>NACCFFTD</th>\n",
       "      <th>NACCFM</th>\n",
       "      <th>NACCBMI</th>\n",
       "      <th>NACCUDSD</th>\n",
       "      <th>DEMENTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>186</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NACC003487</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACC004352</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACC004687</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NACCID  NACCADC PACKET  FORMVER  VISITMO  VISITDAY  VISITYR  NACCVNUM  \\\n",
       "0  NACC002909      186      I      3.0       12        28     2022         1   \n",
       "1  NACC002909      186      F      3.0        1        23     2024         2   \n",
       "2  NACC003487      186      I      3.0       11        15     2023         1   \n",
       "3  NACC004352      186      I      3.0       10         5     2021         1   \n",
       "4  NACC004687      186      I      3.0       11        14     2022         1   \n",
       "\n",
       "   NACCAVST  NACCNVST  ...  INLIVWTH  NACCFAM  NACCMOM  NACCFADM  NACCAM  \\\n",
       "0         2         2  ...       1.0      1.0      0.0         0     9.0   \n",
       "1         2         2  ...       1.0      1.0      0.0         0     9.0   \n",
       "2         1         1  ...       1.0      0.0      0.0         0     9.0   \n",
       "3         1         1  ...       NaN      NaN      NaN         0     NaN   \n",
       "4         1         1  ...       0.0      9.0      0.0         0     9.0   \n",
       "\n",
       "   NACCFFTD  NACCFM  NACCBMI  NACCUDSD  DEMENTED  \n",
       "0         0     9.0     32.4         3         0  \n",
       "1         0     9.0     30.7         3         0  \n",
       "2         0     9.0     23.7         1         0  \n",
       "3         0     NaN    888.8         4         1  \n",
       "4         0     9.0     19.0         1         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/cleaned_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching for target variable...\n",
      "\n",
      "✓ Found: DEMENTED\n",
      "  Value counts: {0: 137606, 1: 57590}\n",
      "  Missing: 0 (0.0%)\n",
      "\n",
      " Selected target variable: DEMENTED\n",
      "   Distribution: {0: 137606, 1: 57590}\n"
     ]
    }
   ],
   "source": [
    "TARGET_CANDIDATES = [\n",
    "    'DEMENTED',     # Binary: 0=Normal, 1=Demented (most direct)\n",
    "    'NORMCOG',      # Binary: 1=Normal cognition\n",
    "    'NACCALZD',     # Alzheimer's disease diagnosis\n",
    "    'NACCALZP',     # Probable AD\n",
    "    'CDRGLOB',      # CDR Global (can convert: 0=normal, >=0.5=impaired)\n",
    "    'NACCCOGF',     # Cognitive status\n",
    "]\n",
    "\n",
    "TARGET = None\n",
    "print(\" Searching for target variable...\\n\")\n",
    "\n",
    "for candidate in TARGET_CANDIDATES:\n",
    "    if candidate in df.columns:\n",
    "        print(f\"✓ Found: {candidate}\")\n",
    "        print(f\"  Value counts: {df[candidate].value_counts().to_dict()}\")\n",
    "        print(f\"  Missing: {df[candidate].isna().sum()} ({df[candidate].isna().sum()/len(df)*100:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        if TARGET is None and candidate == 'DEMENTED':\n",
    "            TARGET = candidate\n",
    "\n",
    "# If DEMENTED not found, use first available\n",
    "if TARGET is None:\n",
    "    for candidate in TARGET_CANDIDATES:\n",
    "        if candidate in df.columns:\n",
    "            TARGET = candidate\n",
    "            break\n",
    "\n",
    "# If still not found, try creating from CDRGLOB\n",
    "if TARGET is None and 'CDRGLOB' in df.columns:\n",
    "    print(\"⚙️  Creating binary target from CDRGLOB\")\n",
    "    print(\"   0 = Normal cognition\")\n",
    "    print(\"   0.5+ = Cognitive impairment/dementia\")\n",
    "    df['DEMENTIA_BINARY'] = (df['CDRGLOB'] >= 0.5).astype(int)\n",
    "    TARGET = 'DEMENTIA_BINARY'\n",
    "\n",
    "if TARGET is None:\n",
    "    print(\"  Could not find or create target variable!\")\n",
    "    print(\"   Available columns that might be targets:\")\n",
    "    possible = [c for c in df.columns if any(x in c.upper() for x in ['DEM', 'COG', 'CDR', 'DIAG'])]\n",
    "    for p in possible[:20]:\n",
    "        print(f\"     - {p}\")\n",
    "else:\n",
    "    print(f\" Selected target variable: {TARGET}\")\n",
    "    print(f\"   Distribution: {df[TARGET].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Target: DEMENTED\n",
      "   Features: 43\n",
      "   Samples: 195,196\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "print(f\" Target: {TARGET}\")\n",
    "print(f\"   Features: {len(X.columns)}\")\n",
    "print(f\"   Samples: {len(X):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Age-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age features created: 5\n",
      "   - age_squared\n",
      "   - age_cubed\n",
      "   - age_group_65, age_group_75, age_group_85\n"
     ]
    }
   ],
   "source": [
    "if 'NACCAGE' in X.columns:\n",
    "\n",
    "    X['age_squared'] = X['NACCAGE'] ** 2\n",
    "    X['age_cubed'] = X['NACCAGE'] ** 3\n",
    "    \n",
    "\n",
    "    X['age_group_65'] = (X['NACCAGE'] >= 65).astype(int)\n",
    "    X['age_group_75'] = (X['NACCAGE'] >= 75).astype(int)\n",
    "    X['age_group_85'] = (X['NACCAGE'] >= 85).astype(int)\n",
    "    \n",
    "    print(\"Age features created: 5\")\n",
    "    print(\"   - age_squared\")\n",
    "    print(\"   - age_cubed\")\n",
    "    print(\"   - age_group_65, age_group_75, age_group_85\")\n",
    "else:\n",
    "    print(\"⚠️  NACCAGE not found, skipping age features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Education Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education features created: 2\n",
      "   - low_education (<12 years)\n",
      "   - high_education (>=16 years)\n",
      "\n",
      " Age-Education interactions: 2\n",
      "   - age_edu_interaction\n",
      "   - age_edu_ratio\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'EDUC' in X.columns:\n",
    "\n",
    "    X['low_education'] = (X['EDUC'] < 12).astype(int)  # Less than high school\n",
    "    X['high_education'] = (X['EDUC'] >= 16).astype(int)  # College graduate+\n",
    "    \n",
    "    print(\"Education features created: 2\")\n",
    "    print(\"   - low_education (<12 years)\")\n",
    "    print(\"   - high_education (>=16 years)\")\n",
    "    \n",
    "    # Age-Education interactions\n",
    "    if 'NACCAGE' in X.columns:\n",
    "        X['age_edu_interaction'] = X['NACCAGE'] * X['EDUC']\n",
    "        X['age_edu_ratio'] = X['NACCAGE'] / (X['EDUC'] + 1)\n",
    "        print(\"\\n Age-Education interactions: 2\")\n",
    "        print(\"   - age_edu_interaction\")\n",
    "        print(\"   - age_edu_ratio\")\n",
    "else:\n",
    "    print(\"⚠️  EDUC not found, skipping education features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Social Isolation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using MARISTAT (marital status)\n",
      "    Using NACCLIVS (living situation)\n",
      "    Using INLIVWTH (informant lives with)\n",
      "\n",
      " Social isolation score created (based on 3 factors)\n",
      "   Distribution: {0: 100287, 3: 43724, 1: 32710, 2: 18475}\n"
     ]
    }
   ],
   "source": [
    "social_isolation = 0\n",
    "factors = 0\n",
    "\n",
    "# Not married\n",
    "if 'MARISTAT' in X.columns:\n",
    "    social_isolation += (X['MARISTAT'] != 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"    Using MARISTAT (marital status)\")\n",
    "\n",
    "# Lives alone\n",
    "if 'NACCLIVS' in X.columns:\n",
    "    social_isolation += (X['NACCLIVS'] == 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"    Using NACCLIVS (living situation)\")\n",
    "\n",
    "# No live-in companion\n",
    "if 'INLIVWTH' in X.columns:\n",
    "    social_isolation += (X['INLIVWTH'] == 0).astype(int)\n",
    "    factors += 1\n",
    "    print(\"    Using INLIVWTH (informant lives with)\")\n",
    "\n",
    "if factors > 0 and isinstance(social_isolation, pd.Series):\n",
    "    X['social_isolation_score'] = social_isolation\n",
    "    print(f\"\\n Social isolation score created (based on {factors} factors)\")\n",
    "    print(f\"   Distribution: {X['social_isolation_score'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"  Cannot create social isolation score (no relevant features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Family Risk Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Using NACCMOM (mother's dementia)\n",
      "   ✓ Using NACCFAM (family history)\n",
      "\n",
      " Family risk features created (based on 2 factors)\n",
      "   family_risk_score distribution: {0: 85416, 2: 70779, 1: 39001}\n",
      "   has_family_history: {1: 109780, 0: 85416}\n"
     ]
    }
   ],
   "source": [
    "family_risk = 0\n",
    "factors = 0\n",
    "\n",
    "\n",
    "if 'NACCMOM' in X.columns:\n",
    "    family_risk += (X['NACCMOM'] == 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"   ✓ Using NACCMOM (mother's dementia)\")\n",
    "\n",
    "if 'NACCDAG' in X.columns:\n",
    "    family_risk += (X['NACCDAG'] == 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"   ✓ Using NACCDAG (father's dementia)\")\n",
    "elif 'NACCFAD' in X.columns:\n",
    "    family_risk += (X['NACCFAD'] == 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"   ✓ Using NACCFAD (father's dementia)\")\n",
    "\n",
    "\n",
    "if 'NACCFAM' in X.columns:\n",
    "    family_risk += (X['NACCFAM'] == 1).astype(int)\n",
    "    factors += 1\n",
    "    print(\"   ✓ Using NACCFAM (family history)\")\n",
    "\n",
    "if factors > 0 and isinstance(family_risk, pd.Series):\n",
    "    X['family_risk_score'] = family_risk\n",
    "    X['has_family_history'] = (family_risk > 0).astype(int)\n",
    "    print(f\"\\n Family risk features created (based on {factors} factors)\")\n",
    "    print(f\"   family_risk_score distribution: {X['family_risk_score'].value_counts().to_dict()}\")\n",
    "    print(f\"   has_family_history: {X['has_family_history'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"⚠️  Cannot create family risk score (no relevant features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Temporal features created: 2\n",
      "   - years_in_study\n",
      "   - months_in_study\n",
      "\n",
      " Visit frequency feature created:\n",
      "   - avg_days_between_visits\n"
     ]
    }
   ],
   "source": [
    "if 'NACCDAYS' in X.columns:\n",
    "    X['years_in_study'] = X['NACCDAYS'] / 365.25\n",
    "    X['months_in_study'] = X['NACCDAYS'] / 30.44\n",
    "    print(\" Temporal features created: 2\")\n",
    "    print(\"   - years_in_study\")\n",
    "    print(\"   - months_in_study\")\n",
    "    \n",
    "    if 'NACCVNUM' in X.columns:\n",
    "        X['avg_days_between_visits'] = X['NACCDAYS'] / (X['NACCVNUM'] + 1)\n",
    "        print(\"\\n Visit frequency feature created:\")\n",
    "        print(\"   - avg_days_between_visits\")\n",
    "else:\n",
    "    print(\"  NACCDAYS not found, skipping temporal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 43\n",
      "New features created: 15\n",
      "Total features: 58\n",
      "Samples: 195,196\n"
     ]
    }
   ],
   "source": [
    "original_features = len(df.columns) - 1  \n",
    "new_features_count = len(X.columns) - original_features\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Original features: {original_features}\")\n",
    "print(f\"New features created: {new_features_count}\")\n",
    "print(f\"Total features: {len(X.columns)}\")\n",
    "print(f\"Samples: {len(X):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = pd.concat([X, y], axis=1)\n",
    "output_path = 'data/engineered_data.csv'\n",
    "df_engineered.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Defined 70 potential non-medical features across 5 categories\n",
      "\n",
      " Features by category:\n",
      "  - visit_info: 12 features\n",
      "  - subject_demographics: 25 features\n",
      "  - coparticipant_demographics: 18 features\n",
      "  - family_history: 13 features\n",
      "  - nacc_derived: 2 features\n"
     ]
    }
   ],
   "source": [
    "NON_MEDICAL_FEATURES = {\n",
    "'visit_info': [\n",
    "        'NACCID',       # Subject ID\n",
    "        'NACCADC',      # ADC at which subject was seen\n",
    "        'PACKET',       # Packet code (I=Initial, F=Follow-up, T=Telephone)\n",
    "        'FORMVER',      # Form version\n",
    "        'VISITMO',      # Visit month\n",
    "        'VISITDAY',     # Visit day\n",
    "        'VISITYR',      # Visit year\n",
    "        'NACCVNUM',     # Visit number (order)\n",
    "        'NACCAVST',     # Total number of all UDS visits\n",
    "        'NACCNVST',     # Total number of in-person visits\n",
    "        'NACCDAYS',     # Days from initial to most recent visit\n",
    "        'NACCFDYS',     # Days from initial to each follow-up\n",
    "    ],\n",
    "    'subject_demographics': [\n",
    "        # Birth & Age\n",
    "        'BIRTHMO',      # Birth month\n",
    "        'BIRTHYR',      # Birth year\n",
    "        'NACCAGE',      # Age at visit *\n",
    "        'NACCAGEB',     # Age at baseline/initial visit\n",
    "        \n",
    "        # Sex & Gender\n",
    "        'SEX',          # Sex (1=Male, 2=Female)\n",
    "        \n",
    "        # Race & Ethnicity\n",
    "        'HISPANIC',     # Hispanic/Latino ethnicity\n",
    "        'HISPOR',       # Hispanic origin\n",
    "        'HISPORX',      # Hispanic origin, other (specify)\n",
    "        'RACE',         # Primary race\n",
    "        'RACEX',        # Race, other (specify)\n",
    "        'RACESEC',      # Second race\n",
    "        'RACESECX',     # Second race, other\n",
    "        'RACETER',      # Third race\n",
    "        'RACETERX',     # Third race, other\n",
    "        'NACCNIHR',     # Derived NIH race category\n",
    "        \n",
    "        # Language\n",
    "        'PRIMLANG',     # Primary language\n",
    "        'PRIMLANX',     # Primary language, other\n",
    "         'EDUC', \n",
    "         # Marital & Living Situation *\n",
    "        'MARISTAT',     # Marital status (1=Married, 2=Widowed, etc.)\n",
    "        'NACCLIVS',     # Living situation (derived)\n",
    "        'INDEPEND',     # Level of independence\n",
    "        'RESIDENC',     # Type of residence\n",
    "        \n",
    "        # Other\n",
    "        'HANDED',       # Handedness (1=Left, 2=Right, 3=Ambidextrous)\n",
    "        'NACCREAS',     # Primary reason for coming to ADC (derived)\n",
    "        'NACCREFR',     # Principal referral source (derived)\n",
    "    ],\n",
    "    'coparticipant_demographics': [\n",
    "        'INBIRMO',      # Co-participant birth month\n",
    "        'INBIRYR',      # Co-participant birth year\n",
    "        'INSEX',        # Co-participant sex\n",
    "        'NEWINF',       # Is this a new co-participant?\n",
    "        \n",
    "        # Co-participant Race/Ethnicity\n",
    "        'INHISP',       # Hispanic/Latino\n",
    "        'INHISPOR',     # Hispanic origin\n",
    "        'INHISPOX',     # Hispanic origin, other\n",
    "        'INRACE',       # Race\n",
    "        'INRACEX',      # Race, other\n",
    "        'INRASEC',      # Second race\n",
    "        'INRASECX',     # Second race, other\n",
    "        'INRATER',      # Third race\n",
    "        'INRATERX',     # Third race, other\n",
    "        \n",
    "        # Co-participant Education & Relationship\n",
    "        'INEDUC',       # Years of education\n",
    "        'INRELTO',      # Relationship to subject \n",
    "        'INRELTOX',     # Relationship, other\n",
    "        'INKNOWN',      # How long known subject (months)\n",
    "        'INLIVWTH',     # Lives with subject? \n",
    "    ],        # Years of education (0-36)\n",
    "    'family_history': [\n",
    "        # General Family History\n",
    "        'NACCFAM',      # Any first-degree family member with cognitive impairment \n",
    "        'NACCMOM',      # Mother with cognitive impairment \n",
    "        'NACCDAG',      # Father with cognitive impairment \n",
    "        # Note: Some datasets might use 'NACCFAD' instead of 'NACCDAG'\n",
    "        \n",
    "        # Genetic Mutations (Alzheimer's)\n",
    "        'NACCFADM',     # Evidence of dominantly inherited AD mutation\n",
    "        'NACCAM',       # Evidence for AD mutation (specific genes)\n",
    "        'NACCAMX',      # AD mutation, other\n",
    "        'NACCAMS',      # Source of evidence for AD mutation\n",
    "        'NACCAMSX',     # Source, other\n",
    "        \n",
    "        # Genetic Mutations (FTLD)\n",
    "        'NACCFFTD',     # Evidence for FTLD mutation\n",
    "        'NACCFM',       # Evidence for FTLD mutation (specific)\n",
    "        'NACCFMX',      # FTLD mutation, other\n",
    "        'NACCFMS',      # Source of evidence\n",
    "        'NACCFMSX',     # Source, other\n",
    "    ],\n",
    "    \n",
    "    'nacc_derived': [\n",
    "        'NACCBMI',      # Body Mass Index (derived, could argue borderline)\n",
    "        'NACCUDSD',     # UDS version\n",
    "    ],\n",
    "}\n",
    "# Flatten the dictionary to get all non-medical features\n",
    "ALL_NON_MEDICAL = []\n",
    "for category, features in NON_MEDICAL_FEATURES.items():\n",
    "    ALL_NON_MEDICAL.extend(features)\n",
    "\n",
    "print(f\" Defined {len(ALL_NON_MEDICAL)} potential non-medical features across {len(NON_MEDICAL_FEATURES)} categories\")\n",
    "print(\"\\n Features by category:\")\n",
    "for category, features in NON_MEDICAL_FEATURES.items():\n",
    "    print(f\"  - {category}: {len(features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Available non-medical features: 43/70\n",
      "Missing features: 27\n",
      "\n",
      "⚠️  Missing features (first 20):\n",
      "     - HISPOR\n",
      "     - HISPORX\n",
      "     - RACEX\n",
      "     - RACESEC\n",
      "     - RACESECX\n",
      "     - RACETER\n",
      "     - RACETERX\n",
      "     - PRIMLANX\n",
      "     - INHISP\n",
      "     - INHISPOR\n",
      "     - INHISPOX\n",
      "     - INRACE\n",
      "     - INRACEX\n",
      "     - INRASEC\n",
      "     - INRASECX\n",
      "     - INRATER\n",
      "     - INRATERX\n",
      "     - INEDUC\n",
      "     - INRELTOX\n",
      "     - INKNOWN\n",
      "\n",
      " Available features:\n",
      "  1. NACCID\n",
      "  2. NACCADC\n",
      "  3. PACKET\n",
      "  4. FORMVER\n",
      "  5. VISITMO\n",
      "  6. VISITDAY\n",
      "  7. VISITYR\n",
      "  8. NACCVNUM\n",
      "  9. NACCAVST\n",
      " 10. NACCNVST\n",
      " 11. NACCDAYS\n",
      " 12. NACCFDYS\n",
      " 13. BIRTHMO\n",
      " 14. BIRTHYR\n",
      " 15. NACCAGE\n",
      " 16. NACCAGEB\n",
      " 17. SEX\n",
      " 18. HISPANIC\n",
      " 19. RACE\n",
      " 20. NACCNIHR\n",
      " 21. PRIMLANG\n",
      " 22. EDUC\n",
      " 23. MARISTAT\n",
      " 24. NACCLIVS\n",
      " 25. INDEPEND\n",
      " 26. RESIDENC\n",
      " 27. HANDED\n",
      " 28. NACCREAS\n",
      " 29. NACCREFR\n",
      " 30. INBIRMO\n",
      " 31. INBIRYR\n",
      " 32. INSEX\n",
      " 33. NEWINF\n",
      " 34. INRELTO\n",
      " 35. INLIVWTH\n",
      " 36. NACCFAM\n",
      " 37. NACCMOM\n",
      " 38. NACCFADM\n",
      " 39. NACCAM\n",
      " 40. NACCFFTD\n",
      " 41. NACCFM\n",
      " 42. NACCBMI\n",
      " 43. NACCUDSD\n"
     ]
    }
   ],
   "source": [
    "available_features = [f for f in ALL_NON_MEDICAL if f in df.columns]\n",
    "missing_features = [f for f in ALL_NON_MEDICAL if f not in df.columns]\n",
    "\n",
    "print(f\" Available non-medical features: {len(available_features)}/{len(ALL_NON_MEDICAL)}\")\n",
    "print(f\"Missing features: {len(missing_features)}\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\n⚠️  Missing features (first 20):\")\n",
    "    for feat in missing_features[:20]:\n",
    "        print(f\"     - {feat}\")\n",
    "\n",
    "print(f\"\\n Available features:\")\n",
    "for i, feat in enumerate(available_features, 1):\n",
    "    print(f\"{i:3d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching for target variable...\n",
      "\n",
      "✓ Found: DEMENTED\n",
      "  Value counts: {0: 137606, 1: 57590}\n",
      "  Missing: 0 (0.0%)\n",
      "\n",
      " Selected target variable: DEMENTED\n",
      "   Distribution: {0: 137606, 1: 57590}\n"
     ]
    }
   ],
   "source": [
    "TARGET_CANDIDATES = [\n",
    "    'DEMENTED',     # Binary: 0=Normal, 1=Demented (most direct)\n",
    "    'NORMCOG',      # Binary: 1=Normal cognition\n",
    "    'NACCALZD',     # Alzheimer's disease diagnosis\n",
    "    'NACCALZP',     # Probable AD\n",
    "    'CDRGLOB',      # CDR Global (can convert: 0=normal, >=0.5=impaired)\n",
    "    'NACCCOGF',     # Cognitive status\n",
    "]\n",
    "\n",
    "TARGET = None\n",
    "print(\" Searching for target variable...\\n\")\n",
    "\n",
    "for candidate in TARGET_CANDIDATES:\n",
    "    if candidate in df.columns:\n",
    "        print(f\"✓ Found: {candidate}\")\n",
    "        print(f\"  Value counts: {df[candidate].value_counts().to_dict()}\")\n",
    "        print(f\"  Missing: {df[candidate].isna().sum()} ({df[candidate].isna().sum()/len(df)*100:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        if TARGET is None and candidate == 'DEMENTED':\n",
    "            TARGET = candidate\n",
    "\n",
    "# If DEMENTED not found, use first available\n",
    "if TARGET is None:\n",
    "    for candidate in TARGET_CANDIDATES:\n",
    "        if candidate in df.columns:\n",
    "            TARGET = candidate\n",
    "            break\n",
    "\n",
    "# If still not found, try creating from CDRGLOB\n",
    "if TARGET is None and 'CDRGLOB' in df.columns:\n",
    "    print(\"⚙️  Creating binary target from CDRGLOB\")\n",
    "    print(\"   0 = Normal cognition\")\n",
    "    print(\"   0.5+ = Cognitive impairment/dementia\")\n",
    "    df['DEMENTIA_BINARY'] = (df['CDRGLOB'] >= 0.5).astype(int)\n",
    "    TARGET = 'DEMENTIA_BINARY'\n",
    "\n",
    "if TARGET is None:\n",
    "    print(\"  Could not find or create target variable!\")\n",
    "    print(\"   Available columns that might be targets:\")\n",
    "    possible = [c for c in df.columns if any(x in c.upper() for x in ['DEM', 'COG', 'CDR', 'DIAG'])]\n",
    "    for p in possible[:20]:\n",
    "        print(f\"     - {p}\")\n",
    "else:\n",
    "    print(f\" Selected target variable: {TARGET}\")\n",
    "    print(f\"   Distribution: {df[TARGET].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating warking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Working dataset created!\n",
      "   - Initial rows: 195,196\n",
      "   - Removed (missing target): 0\n",
      "   - Final rows: 195,196\n",
      "   - Features: 43\n",
      "   - Target: DEMENTED\n",
      "\n",
      "   Target distribution:\n",
      "     0: 137,606 (70.5%)\n",
      "     1: 57,590 (29.5%)\n"
     ]
    }
   ],
   "source": [
    "df_work = df[available_features + [TARGET]].copy()\n",
    "\n",
    "# Remove rows where target is missing\n",
    "initial_count = len(df_work)\n",
    "df_work = df_work[df_work[TARGET].notna()]\n",
    "removed_count = initial_count - len(df_work)\n",
    "\n",
    "print(f\" Working dataset created!\")\n",
    "print(f\"   - Initial rows: {initial_count:,}\")\n",
    "print(f\"   - Removed (missing target): {removed_count:,}\")\n",
    "print(f\"   - Final rows: {len(df_work):,}\")\n",
    "print(f\"   - Features: {len(available_features)}\")\n",
    "print(f\"   - Target: {TARGET}\")\n",
    "print(f\"\\n   Target distribution:\")\n",
    "for value, count in df_work[TARGET].value_counts().items():\n",
    "    pct = count / len(df_work) * 100\n",
    "    print(f\"     {value}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "handle NACC special   codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Handling NACC special codes...\n",
      "   Converting to NaN: {MISSING_CODES}\n",
      "\n",
      "   No special codes found\n",
      "\n",
      " Special codes converted to NaN\n"
     ]
    }
   ],
   "source": [
    "MISSING_CODES = [-4, 88, 888, 8888, 99, 999, 9999]\n",
    "\n",
    "print(\" Handling NACC special codes...\")\n",
    "print(\"   Converting to NaN: {MISSING_CODES}\\n\")\n",
    "\n",
    "# Count occurrences before replacement\n",
    "codes_found = {}\n",
    "for code in MISSING_CODES:\n",
    "    count = (df_work == code).sum().sum()\n",
    "    if count > 0:\n",
    "        codes_found[code] = count\n",
    "\n",
    "if codes_found:\n",
    "    print(\"   Special codes found:\")\n",
    "    for code, count in sorted(codes_found.items()):\n",
    "        print(f\"     {code}: {count:,} occurrences\")\n",
    "else:\n",
    "    print(\"   No special codes found\")\n",
    "\n",
    "# Replace with NaN (except in target)\n",
    "for col in df_work.columns:\n",
    "    if col != TARGET:\n",
    "        df_work[col] = df_work[col].replace(MISSING_CODES, np.nan)\n",
    "\n",
    "print(\"\\n Special codes converted to NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "      <th>Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NACCFM</th>\n",
       "      <td>NACCFM</td>\n",
       "      <td>61950</td>\n",
       "      <td>31.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCAM</th>\n",
       "      <td>NACCAM</td>\n",
       "      <td>61950</td>\n",
       "      <td>31.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWINF</th>\n",
       "      <td>NEWINF</td>\n",
       "      <td>58060</td>\n",
       "      <td>29.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCBMI</th>\n",
       "      <td>NACCBMI</td>\n",
       "      <td>25911</td>\n",
       "      <td>13.27</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INBIRMO</th>\n",
       "      <td>INBIRMO</td>\n",
       "      <td>14061</td>\n",
       "      <td>7.20</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INBIRYR</th>\n",
       "      <td>INBIRYR</td>\n",
       "      <td>13835</td>\n",
       "      <td>7.09</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INLIVWTH</th>\n",
       "      <td>INLIVWTH</td>\n",
       "      <td>8288</td>\n",
       "      <td>4.25</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSEX</th>\n",
       "      <td>INSEX</td>\n",
       "      <td>8288</td>\n",
       "      <td>4.25</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INRELTO</th>\n",
       "      <td>INRELTO</td>\n",
       "      <td>8288</td>\n",
       "      <td>4.25</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCAGE</th>\n",
       "      <td>NACCAGE</td>\n",
       "      <td>3596</td>\n",
       "      <td>1.84</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCNIHR</th>\n",
       "      <td>NACCNIHR</td>\n",
       "      <td>2559</td>\n",
       "      <td>1.31</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCFAM</th>\n",
       "      <td>NACCFAM</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.06</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCMOM</th>\n",
       "      <td>NACCMOM</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.06</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCAGEB</th>\n",
       "      <td>NACCAGEB</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.84</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUC</th>\n",
       "      <td>EDUC</td>\n",
       "      <td>974</td>\n",
       "      <td>0.50</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACE</th>\n",
       "      <td>RACE</td>\n",
       "      <td>832</td>\n",
       "      <td>0.43</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCFDYS</th>\n",
       "      <td>NACCFDYS</td>\n",
       "      <td>61</td>\n",
       "      <td>0.03</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACCDAYS</th>\n",
       "      <td>NACCDAYS</td>\n",
       "      <td>37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column  Missing_Count  Missing_Percentage    Dtype\n",
       "NACCFM      NACCFM          61950               31.74  float64\n",
       "NACCAM      NACCAM          61950               31.74  float64\n",
       "NEWINF      NEWINF          58060               29.74  float64\n",
       "NACCBMI    NACCBMI          25911               13.27  float64\n",
       "INBIRMO    INBIRMO          14061                7.20  float64\n",
       "INBIRYR    INBIRYR          13835                7.09  float64\n",
       "INLIVWTH  INLIVWTH           8288                4.25  float64\n",
       "INSEX        INSEX           8288                4.25  float64\n",
       "INRELTO    INRELTO           8288                4.25  float64\n",
       "NACCAGE    NACCAGE           3596                1.84  float64\n",
       "NACCNIHR  NACCNIHR           2559                1.31  float64\n",
       "NACCFAM    NACCFAM           2070                1.06  float64\n",
       "NACCMOM    NACCMOM           2070                1.06  float64\n",
       "NACCAGEB  NACCAGEB           1636                0.84  float64\n",
       "EDUC          EDUC            974                0.50  float64\n",
       "RACE          RACE            832                0.43  float64\n",
       "NACCFDYS  NACCFDYS             61                0.03  float64\n",
       "NACCDAYS  NACCDAYS             37                0.02  float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df_work.columns,\n",
    "    'Missing_Count': df_work.isnull().sum(),\n",
    "    'Missing_Percentage': (df_work.isnull().sum() / len(df_work) * 100).round(2),\n",
    "    'Dtype': df_work.dtypes\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "total_cells = df_work.shape[0] * df_work.shape[1]\n",
    "missing_cells = df_work.isnull().sum().sum()\n",
    "missing_pct = (missing_cells / total_cells * 100)\n",
    "\n",
    "missing_stats[missing_stats['Missing_Count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Remove High-Missing Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No features with >50.0% missing\n",
      "\n",
      "Remaining features: 43  (+ target)\n"
     ]
    }
   ],
   "source": [
    "MISSING_THRESHOLD = 50.0\n",
    "\n",
    "high_missing = missing_stats[missing_stats['Missing_Percentage'] > MISSING_THRESHOLD]\n",
    "cols_to_remove = high_missing['Column'].tolist()\n",
    "\n",
    "# Don't remove target\n",
    "if TARGET in cols_to_remove:\n",
    "    cols_to_remove.remove(TARGET)\n",
    "\n",
    "if cols_to_remove:\n",
    "    print(f\"Removing {len(cols_to_remove)} features with >{MISSING_THRESHOLD}% missing:\")\n",
    "    for col in cols_to_remove:\n",
    "        pct = high_missing[high_missing['Column'] == col]['Missing_Percentage'].values[0]\n",
    "        print(f\"  - {col}: {pct:.1f}% missing\")\n",
    "    \n",
    "    df_work = df_work.drop(columns=cols_to_remove)\n",
    "    print(f\"\\n Removed {len(cols_to_remove)} high-missing features\")\n",
    "else:\n",
    "    print(f\" No features with >{MISSING_THRESHOLD}% missing\")\n",
    "\n",
    "print(f\"\\nRemaining features: {df_work.shape[1] - 1}  (+ target)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found: 0\n",
      "  No duplicates found\n",
      "\n",
      "Rows after duplicate removal: 195,196\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_rows = len(df_work)\n",
    "duplicates = df_work.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicate rows found: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"  Removing {duplicates} duplicate rows...\")\n",
    "    df_work = df_work.drop_duplicates()\n",
    "    print(f\"  Removed {duplicates} duplicates\")\n",
    "else:\n",
    "    print(f\"  No duplicates found\")\n",
    "\n",
    "print(f\"\\nRows after duplicate removal: {len(df_work):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before optimization: 85.82 MB\n"
     ]
    }
   ],
   "source": [
    "memory_before = df_work.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"Memory before optimization: {memory_before:.2f} MB\")\n",
    "\n",
    "# Convert float64 to float32 where possible\n",
    "float_cols = df_work.select_dtypes(include=['float64']).columns\n",
    "for col in float_cols:\n",
    "    if col != TARGET:\n",
    "        df_work[col] = df_work[col].astype('float32')\n",
    "\n",
    "# Convert int64 to int32 where possible\n",
    "int_cols = df_work.select_dtypes(include=['int64']).columns\n",
    "for col in int_cols:\n",
    "    if col != TARGET:\n",
    "        # Check if values fit in int32\n",
    "        if df_work[col].max() < 2147483647 and df_work[col].min() > -2147483648:\n",
    "            df_work[col] = df_work[col].astype('int32')\n",
    "\n",
    "memory_after = df_work.memory_usage(deep=True).sum() / 1024**2\n",
    "memory_saved = memory_before - memory_after\n",
    "memory_saved_pct = (memory_saved / memory_before * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'original_rows': len(df),\n",
    "    'original_columns': len(df.columns),\n",
    "    'cleaned_rows': len(df_work),\n",
    "    'cleaned_columns': len(df_work.columns),\n",
    "    'rows_removed': len(df) - len(df_work),\n",
    "    'features_removed': len(cols_to_remove) if cols_to_remove else 0,\n",
    "    'special_codes_converted': total_special if codes_found else 0,\n",
    "    'duplicates_removed': duplicates,\n",
    "    'final_missing_percentage': round((df_work.isnull().sum().sum() / (df_work.shape[0] * df_work.shape[1]) * 100), 2),\n",
    "    'memory_saved_mb': round(memory_saved, 2),\n",
    "    'target_variable': TARGET\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'data/cleaned_data.csv'\n",
    "df_work.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
